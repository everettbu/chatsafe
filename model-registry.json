{
  "models": [
    {
      "id": "llama-3.2-3b-instruct-q4_k_m",
      "name": "Llama 3.2 3B Instruct",
      "version": "3.2",
      "quantization": "Q4_K_M",
      "size_gb": 2.0,
      "context_window": 8192,
      "template": {
        "format": "llama-3-instruct",
        "system_prefix": "<|start_header_id|>system<|end_header_id|>\n\n",
        "system_suffix": "<|eot_id|>",
        "user_prefix": "<|start_header_id|>user<|end_header_id|>\n\n",
        "user_suffix": "<|eot_id|>",
        "assistant_prefix": "<|start_header_id|>assistant<|end_header_id|>\n\n",
        "assistant_suffix": "<|eot_id|>",
        "begin_of_text": "<|begin_of_text|>",
        "end_of_text": "<|end_of_text|>"
      },
      "stop_sequences": [
        "<|eot_id|>",
        "<|end_of_text|>",
        "<|start_header_id|>"
      ],
      "default_parameters": {
        "temperature": 0.6,
        "top_p": 0.9,
        "top_k": 40,
        "repeat_penalty": 1.15,
        "max_tokens": 256
      },
      "performance": {
        "tokens_per_second": {
          "m4_mac": "50-70"
        },
        "first_token_latency_ms": {
          "m4_mac": "<500"
        }
      },
      "capabilities": {
        "instruction_following": true,
        "chat": true,
        "code_generation": true,
        "reasoning": true,
        "math": true
      },
      "file_path": "~/.local/share/chatsafe/models/llama-3.2-3b-instruct-q4_k_m.gguf",
      "hash": "placeholder_sha256",
      "last_updated": "2025-09-30"
    }
  ],
  "registry_version": "1.0.0"
}